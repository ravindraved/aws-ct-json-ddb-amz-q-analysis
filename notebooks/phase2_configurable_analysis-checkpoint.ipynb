{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Configurable CloudTrail Analysis\n",
    "\n",
    "This notebook allows you to analyze CloudTrail data for any date or date range, with automatic validation that Phase 1 data exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Add src to path\n",
    "src_path = Path('../src').resolve()\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from phase2.duckdb_connector import DuckDBConnector\n",
    "from phase2.query_templates import QueryTemplates\n",
    "from phase2.cloudtrail_schema import CloudTrailSchema\n",
    "from phase2.data_validator import Phase1DataValidator\n",
    "from common.logging_config import setup_logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration - Set Your Date Range Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… Analysis Configuration:\n",
      "  Start Date: 2025-07-25\n",
      "  End Date: 2025-07-31\n",
      "  Data Path: ../data\n",
      "  Database: ../data/analysis_20250725.duckdb\n"
     ]
    }
   ],
   "source": [
    "# ===== CONFIGURATION SECTION =====\n",
    "# Modify these parameters for your analysis\n",
    "\n",
    "# Date configuration (YYYY-MM-DD format)\n",
    "START_DATE = \"2025-07-25\"  # Required: Start date for analysis\n",
    "END_DATE = \"2025-07-31\"\n",
    "# END_DATE = None            # Optional: End date for range analysis (None for single day)\n",
    "\n",
    "# Alternative: Uncomment for date range analysis\n",
    "# START_DATE = \"2025-08-06\"\n",
    "# END_DATE = \"2025-08-07\"\n",
    "\n",
    "# Paths\n",
    "BASE_DATA_PATH = \"../data\"\n",
    "DB_PATH = f\"../data/analysis_{START_DATE.replace('-', '')}.duckdb\"\n",
    "\n",
    "# Logging\n",
    "LOG_LEVEL = \"INFO\"\n",
    "\n",
    "print(f\"ğŸ“… Analysis Configuration:\")\n",
    "print(f\"  Start Date: {START_DATE}\")\n",
    "print(f\"  End Date: {END_DATE if END_DATE else 'Same as start date'}\")\n",
    "print(f\"  Data Path: {BASE_DATA_PATH}\")\n",
    "print(f\"  Database: {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking Phase 1 data availability...\n",
      "\n",
      "ğŸ“Š Available data dates: 14 days\n",
      "  Range: 07-30-.ipynb_checkpoints to 2025-08-07\n",
      "  Dates: 07-30-.ipynb_checkpoints, 2025-07-25, 2025-07-26, 2025-07-27, 2025-07-28, 2025-07-29, 2025-07-30, 2025-07-31, 2025-08-01, 2025-08-02...\n",
      "[2025-08-08 14:43:07] [INFO] [cloudtrail_analyzer.data_validator] [validate_date_range] - Date validation: 7 available, 0 missing\n",
      "\n",
      "âœ… Validation Results:\n",
      "  Requested dates available: True\n",
      "  Available dates: ['2025-07-25', '2025-07-26', '2025-07-27', '2025-07-28', '2025-07-29', '2025-07-30', '2025-07-31']\n",
      "  ğŸ“ˆ Estimated files to process: 2041\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logger = setup_logging(log_level=LOG_LEVEL)\n",
    "\n",
    "# Initialize data validator\n",
    "validator = Phase1DataValidator(BASE_DATA_PATH)\n",
    "\n",
    "print(\"ğŸ” Checking Phase 1 data availability...\")\n",
    "\n",
    "# Check what dates are available\n",
    "available_ranges = validator.get_available_date_ranges()\n",
    "print(f\"\\nğŸ“Š Available data dates: {len(available_ranges)} days\")\n",
    "if available_ranges:\n",
    "    print(f\"  Range: {min(available_ranges)} to {max(available_ranges)}\")\n",
    "    print(f\"  Dates: {', '.join(available_ranges[:10])}{'...' if len(available_ranges) > 10 else ''}\")\n",
    "else:\n",
    "    print(\"  âŒ No processed data found! Please run Phase 1 first.\")\n",
    "\n",
    "# Validate requested date range\n",
    "all_available, available_dates, missing_dates = validator.validate_date_range(START_DATE, END_DATE)\n",
    "\n",
    "print(f\"\\nâœ… Validation Results:\")\n",
    "print(f\"  Requested dates available: {all_available}\")\n",
    "print(f\"  Available dates: {available_dates}\")\n",
    "if missing_dates:\n",
    "    print(f\"  âŒ Missing dates: {missing_dates}\")\n",
    "    print(f\"  âš ï¸  Please run Phase 1 for missing dates before proceeding.\")\n",
    "\n",
    "# Count events for the date range\n",
    "event_count = validator.count_events_for_date_range(START_DATE, END_DATE)\n",
    "print(f\"  ğŸ“ˆ Estimated files to process: {event_count}\")\n",
    "\n",
    "if not all_available:\n",
    "    print(\"\\nâš ï¸  WARNING: Some requested dates are missing. Analysis will only include available dates.\")\n",
    "    proceed = input(\"Do you want to proceed with available data only? (y/n): \")\n",
    "    if proceed.lower() != 'y':\n",
    "        print(\"Analysis cancelled. Please run Phase 1 for missing dates.\")\n",
    "        raise SystemExit(\"Analysis cancelled by user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DuckDB and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Initializing DuckDB connection...\n",
      "[2025-08-08 14:43:11] [INFO] [cloudtrail_analyzer.duckdb_connector] [connect] - Connected to DuckDB at ../data/analysis_20250725.duckdb\n",
      "ğŸ“‚ Using data path: /home/ec2-user/prj_ws/pyprj/ct-ddb-json/data/processed\n",
      "ğŸ“Š Creating CloudTrail view...\n",
      "[2025-08-08 14:43:13] [INFO] [cloudtrail_analyzer.duckdb_connector] [create_cloudtrail_view] - Created CloudTrail view 'cloudtrail' from /home/ec2-user/prj_ws/pyprj/ct-ddb-json/data/processed\n",
      "âœ… CloudTrail view created successfully\n",
      "[2025-08-08 14:43:17] [INFO] [cloudtrail_analyzer.duckdb_connector] [execute_query] - Query returned 1 rows\n",
      "\n",
      "ğŸ“ˆ Data loaded successfully:\n",
      "  Total events in date range: 93,923\n"
     ]
    }
   ],
   "source": [
    "if not available_dates:\n",
    "    raise SystemExit(\"No data available for analysis. Please run Phase 1 first.\")\n",
    "\n",
    "print(\"ğŸ”— Initializing DuckDB connection...\")\n",
    "db = DuckDBConnector(DB_PATH)\n",
    "\n",
    "# Get data path for the validated date range\n",
    "data_path = validator.get_data_path_for_dates(START_DATE, END_DATE)\n",
    "print(f\"ğŸ“‚ Using data path: {data_path}\")\n",
    "\n",
    "# Create CloudTrail view with date filtering\n",
    "print(\"ğŸ“Š Creating CloudTrail view...\")\n",
    "success = db.create_cloudtrail_view(data_path)\n",
    "\n",
    "if not success:\n",
    "    raise SystemExit(\"Failed to create CloudTrail view. Check data path and format.\")\n",
    "\n",
    "print(\"âœ… CloudTrail view created successfully\")\n",
    "\n",
    "# Test data loading and apply date filter\n",
    "date_filter = f\"eventTime >= '{START_DATE}'\"\n",
    "if END_DATE:\n",
    "    date_filter += f\" AND eventTime <= '{END_DATE} 23:59:59'\"\n",
    "\n",
    "test_query = f\"SELECT COUNT(*) as total_events FROM cloudtrail WHERE {date_filter}\"\n",
    "result = db.execute_query(test_query)\n",
    "total_events = result.iloc[0]['total_events']\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Data loaded successfully:\")\n",
    "print(f\"  Total events in date range: {total_events:,}\")\n",
    "\n",
    "if total_events == 0:\n",
    "    print(\"âš ï¸  No events found in the specified date range. Check your date configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview for Selected Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3eb68f81254f39aa43a43140fe2691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 14:43:27] [INFO] [cloudtrail_analyzer.duckdb_connector] [execute_query] - Query returned 1 rows\n",
      "============================================================\n",
      "ğŸ“Š CLOUDTRAIL ANALYSIS: 2025-07-25 to 2025-07-31\n",
      "============================================================\n",
      "  Total Events: 93923\n",
      "  Unique Services: 132\n",
      "  Unique Events: 583\n",
      "  Unique Ips: 55\n",
      "  Earliest Event: 2025-07-25 00:01:03\n",
      "  Latest Event: 2025-07-31 23:58:14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427f68cd76944403a2e8ee917b048cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 14:43:31] [INFO] [cloudtrail_analyzer.duckdb_connector] [execute_query] - Query returned 10 rows\n",
      "\n",
      "ğŸ† Top AWS Services (2025-07-25 to 2025-07-31):\n",
      "  tagging.amazonaws.com: 27,800 events\n",
      "  sts.amazonaws.com: 21,488 events\n",
      "  s3.amazonaws.com: 15,141 events\n",
      "  config.amazonaws.com: 5,741 events\n",
      "  kms.amazonaws.com: 4,584 events\n",
      "  ssm.amazonaws.com: 4,323 events\n",
      "  ec2.amazonaws.com: 3,015 events\n",
      "  logs.amazonaws.com: 2,237 events\n",
      "  events.amazonaws.com: 883 events\n",
      "  notifications.amazonaws.com: 794 events\n"
     ]
    }
   ],
   "source": [
    "if total_events > 0:\n",
    "    # Data overview with date filtering\n",
    "    overview_query = f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_events,\n",
    "        COUNT(DISTINCT eventSource) as unique_services,\n",
    "        COUNT(DISTINCT eventName) as unique_events,\n",
    "        COUNT(DISTINCT sourceIPAddress) as unique_ips,\n",
    "        MIN(eventTime) as earliest_event,\n",
    "        MAX(eventTime) as latest_event\n",
    "    FROM cloudtrail \n",
    "    WHERE {date_filter}\n",
    "    \"\"\"\n",
    "    \n",
    "    overview = db.execute_query(overview_query)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ“Š CLOUDTRAIL ANALYSIS: {START_DATE}\" + (f\" to {END_DATE}\" if END_DATE else \"\"))\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for col in overview.columns:\n",
    "        value = overview.iloc[0][col]\n",
    "        print(f\"  {col.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    # Top services for the date range\n",
    "    services_query = f\"\"\"\n",
    "    SELECT \n",
    "        eventSource,\n",
    "        COUNT(*) as event_count,\n",
    "        COUNT(DISTINCT eventName) as unique_events\n",
    "    FROM cloudtrail \n",
    "    WHERE {date_filter}\n",
    "    GROUP BY eventSource\n",
    "    ORDER BY event_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    \n",
    "    services = db.execute_query(services_query)\n",
    "    print(f\"\\nğŸ† Top AWS Services ({START_DATE}\" + (f\" to {END_DATE}\" if END_DATE else \"\") + \"):\")\n",
    "    for _, row in services.iterrows():\n",
    "        print(f\"  {row['eventSource']}: {row['event_count']:,} events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security Analysis for Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”’ SECURITY ANALYSIS\n",
      "==================================================\n",
      "\n",
      "ğŸ” Unusual API Calls (2025-07-29 to 2025-07-31):\n",
      "[2025-08-08 11:50:20] [INFO] [cloudtrail_analyzer.duckdb_connector] [execute_query] - Query returned 227 rows\n",
      "  Found 227 unusual API patterns\n",
      "  - ListScripts: 1 calls from 1 IPs\n",
      "  - RunInstances: 1 calls from 1 IPs\n",
      "  - SharedSnapshotVolumeCreated: 1 calls from 1 IPs\n",
      "  - GetBuckets: 1 calls from 1 IPs\n",
      "  - DescribeImageBuilders: 1 calls from 1 IPs\n",
      "\n",
      "ğŸ” Privilege Escalation Events:\n",
      "[2025-08-08 11:50:23] [INFO] [cloudtrail_analyzer.duckdb_connector] [execute_query] - Query returned 9350 rows\n",
      "  âš ï¸  Found 9350 privilege escalation events\n",
      "  - 2025-07-31 23:58:09: AssumeRole by None\n",
      "  - 2025-07-31 23:52:26: AssumeRole by None\n",
      "  - 2025-07-31 23:49:08: AssumeRole by None\n"
     ]
    }
   ],
   "source": [
    "if total_events > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ”’ SECURITY ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Initialize query templates\n",
    "    templates = QueryTemplates()\n",
    "    \n",
    "    # Modify security queries to include date filter\n",
    "    unusual_template = templates.get_template('unusual_api_calls')\n",
    "    if unusual_template:\n",
    "        # Add date filter to the query\n",
    "        modified_query = unusual_template.sql.replace(\n",
    "            \"FROM cloudtrail\", \n",
    "            f\"FROM cloudtrail WHERE {date_filter}\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ” {unusual_template.name} ({START_DATE}\" + (f\" to {END_DATE}\" if END_DATE else \"\") + \"):\")\n",
    "        unusual_results = db.execute_query(modified_query)\n",
    "        \n",
    "        if not unusual_results.empty:\n",
    "            print(f\"  Found {len(unusual_results)} unusual API patterns\")\n",
    "            for _, row in unusual_results.head(5).iterrows():\n",
    "                print(f\"  - {row['eventName']}: {row['call_count']} calls from {row['unique_ips']} IPs\")\n",
    "        else:\n",
    "            print(\"  âœ… No unusual API calls detected\")\n",
    "    \n",
    "    # Check for privilege escalation in date range\n",
    "    priv_template = templates.get_template('privilege_escalation')\n",
    "    if priv_template:\n",
    "        # Add date filter to existing WHERE clause\n",
    "        modified_query = priv_template.sql.replace(\n",
    "            \"WHERE eventName IN\", \n",
    "            f\"WHERE {date_filter} AND eventName IN\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ” {priv_template.name}:\")\n",
    "        priv_results = db.execute_query(modified_query)\n",
    "        \n",
    "        if not priv_results.empty:\n",
    "            print(f\"  âš ï¸  Found {len(priv_results)} privilege escalation events\")\n",
    "            for _, row in priv_results.head(3).iterrows():\n",
    "                print(f\"  - {row['eventTime']}: {row['eventName']} by {row['userName']}\")\n",
    "        else:\n",
    "            print(\"  âœ… No privilege escalation events detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Analysis for Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”§ CUSTOM ANALYSIS\n",
      "==================================================\n",
      "\n",
      "ğŸ“ˆ Hourly Activity Timeline:\n",
      "[2025-08-08 11:50:26] [INFO] [cloudtrail_analyzer.duckdb_connector] [execute_query] - Query returned 73 rows\n",
      "  2025-07-29 00:00:00 00:00 - 157 events (26 services)\n",
      "  2025-07-29 00:00:00 01:00 - 596 events (32 services)\n",
      "  2025-07-29 00:00:00 02:00 - 151 events (24 services)\n",
      "  2025-07-29 00:00:00 03:00 - 745 events (20 services)\n",
      "  2025-07-29 00:00:00 04:00 - 1,115 events (34 services)\n",
      "  2025-07-29 00:00:00 05:00 - 125 events (27 services)\n",
      "  2025-07-29 00:00:00 06:00 - 1,442 events (35 services)\n",
      "  2025-07-29 00:00:00 07:00 - 268 events (30 services)\n",
      "  2025-07-29 00:00:00 08:00 - 127 events (24 services)\n",
      "  2025-07-29 00:00:00 09:00 - 217 events (24 services)\n",
      "  2025-07-29 00:00:00 10:00 - 1,029 events (18 services)\n",
      "  2025-07-29 00:00:00 11:00 - 256 events (31 services)\n",
      "  2025-07-29 00:00:00 12:00 - 181 events (30 services)\n",
      "  2025-07-29 00:00:00 13:00 - 126 events (20 services)\n",
      "  2025-07-29 00:00:00 14:00 - 131 events (28 services)\n",
      "  2025-07-29 00:00:00 15:00 - 770 events (21 services)\n",
      "  2025-07-29 00:00:00 16:00 - 1,112 events (28 services)\n",
      "  2025-07-29 00:00:00 17:00 - 378 events (30 services)\n",
      "  2025-07-29 00:00:00 18:00 - 494 events (45 services)\n",
      "  2025-07-29 00:00:00 19:00 - 1,296 events (48 services)\n",
      "  2025-07-29 00:00:00 20:00 - 649 events (24 services)\n",
      "  2025-07-29 00:00:00 21:00 - 318 events (36 services)\n",
      "  2025-07-29 00:00:00 22:00 - 958 events (31 services)\n",
      "  2025-07-29 00:00:00 23:00 - 249 events (33 services)\n",
      "  2025-07-30 00:00:00 00:00 - 168 events (26 services)\n",
      "  2025-07-30 00:00:00 01:00 - 600 events (39 services)\n",
      "  2025-07-30 00:00:00 02:00 - 136 events (27 services)\n",
      "  2025-07-30 00:00:00 03:00 - 743 events (24 services)\n",
      "  2025-07-30 00:00:00 04:00 - 1,105 events (30 services)\n",
      "  2025-07-30 00:00:00 05:00 - 623 events (31 services)\n",
      "  2025-07-30 00:00:00 06:00 - 1,273 events (39 services)\n",
      "  2025-07-30 00:00:00 07:00 - 819 events (42 services)\n",
      "  2025-07-30 00:00:00 08:00 - 215 events (30 services)\n",
      "  2025-07-30 00:00:00 09:00 - 229 events (28 services)\n",
      "  2025-07-30 00:00:00 10:00 - 1,108 events (22 services)\n",
      "  2025-07-30 00:00:00 11:00 - 269 events (37 services)\n",
      "  2025-07-30 00:00:00 12:00 - 165 events (33 services)\n",
      "  2025-07-30 00:00:00 13:00 - 122 events (20 services)\n",
      "  2025-07-30 00:00:00 14:00 - 119 events (26 services)\n",
      "  2025-07-30 00:00:00 15:00 - 754 events (24 services)\n",
      "  2025-07-30 00:00:00 16:00 - 1,037 events (35 services)\n",
      "  2025-07-30 00:00:00 17:00 - 125 events (25 services)\n",
      "  2025-07-30 00:00:00 18:00 - 608 events (41 services)\n",
      "  2025-07-30 00:00:00 19:00 - 1,372 events (55 services)\n",
      "  2025-07-30 00:00:00 20:00 - 545 events (17 services)\n",
      "  2025-07-30 00:00:00 21:00 - 323 events (35 services)\n",
      "  2025-07-30 00:00:00 22:00 - 1,154 events (32 services)\n",
      "  2025-07-30 00:00:00 23:00 - 250 events (35 services)\n",
      "  2025-07-31 00:00:00 00:00 - 157 events (28 services)\n",
      "  2025-07-31 00:00:00 01:00 - 596 events (36 services)\n",
      "  2025-07-31 00:00:00 02:00 - 122 events (24 services)\n",
      "  2025-07-31 00:00:00 03:00 - 757 events (22 services)\n",
      "  2025-07-31 00:00:00 04:00 - 1,027 events (36 services)\n",
      "  2025-07-31 00:00:00 05:00 - 118 events (23 services)\n",
      "  2025-07-31 00:00:00 06:00 - 525 events (29 services)\n",
      "  2025-07-31 00:00:00 07:00 - 1,325 events (46 services)\n",
      "  2025-07-31 00:00:00 08:00 - 152 events (29 services)\n",
      "  2025-07-31 00:00:00 09:00 - 228 events (33 services)\n",
      "  2025-07-31 00:00:00 10:00 - 1,103 events (29 services)\n",
      "  2025-07-31 00:00:00 11:00 - 178 events (29 services)\n",
      "  2025-07-31 00:00:00 12:00 - 151 events (31 services)\n",
      "  2025-07-31 00:00:00 13:00 - 136 events (24 services)\n",
      "  2025-07-31 00:00:00 14:00 - 127 events (24 services)\n",
      "  2025-07-31 00:00:00 15:00 - 777 events (31 services)\n",
      "  2025-07-31 00:00:00 16:00 - 1,239 events (34 services)\n",
      "  2025-07-31 00:00:00 17:00 - 1,565 events (29 services)\n",
      "  2025-07-31 00:00:00 18:00 - 625 events (38 services)\n",
      "  2025-07-31 00:00:00 19:00 - 1,127 events (0 services)\n",
      "  2025-07-31 00:00:00 19:00 - 424 events (58 services)\n",
      "  2025-07-31 00:00:00 20:00 - 636 events (23 services)\n",
      "  2025-07-31 00:00:00 21:00 - 328 events (34 services)\n",
      "  2025-07-31 00:00:00 22:00 - 1,042 events (27 services)\n",
      "  2025-07-31 00:00:00 23:00 - 231 events (28 services)\n",
      "\n",
      "ğŸ‘¥ Top Active Users/Roles:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703a864ea48d4bc5b11d4897d128d9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 11:50:29] [INFO] [cloudtrail_analyzer.duckdb_connector] [execute_query] - Query returned 2 rows\n",
      "  AssumedRole: N/A - 30,047 actions\n",
      "  AWSService: N/A - 11,382 actions\n"
     ]
    }
   ],
   "source": [
    "if total_events > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ”§ CUSTOM ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Timeline analysis for the date range\n",
    "    timeline_query = f\"\"\"\n",
    "    SELECT \n",
    "        DATE(CAST(eventTime AS TIMESTAMP)) as event_date,\n",
    "        HOUR(CAST(eventTime AS TIMESTAMP)) as event_hour,\n",
    "        COUNT(*) as event_count,\n",
    "        COUNT(DISTINCT eventSource) as unique_services\n",
    "    FROM cloudtrail \n",
    "    WHERE {date_filter}\n",
    "    GROUP BY DATE(CAST(eventTime AS TIMESTAMP)), HOUR(CAST(eventTime AS TIMESTAMP))\n",
    "    ORDER BY event_date, event_hour\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Hourly Activity Timeline:\")\n",
    "    timeline = db.execute_query(timeline_query)\n",
    "    \n",
    "    if not timeline.empty:\n",
    "        for _, row in timeline.iterrows():\n",
    "            print(f\"  {row['event_date']} {row['event_hour']:02d}:00 - {row['event_count']:,} events ({row['unique_services']} services)\")\n",
    "    \n",
    "    # Top users/roles in the date range\n",
    "    users_query = f\"\"\"\n",
    "    SELECT \n",
    "        json_extract_string(userIdentity, '$.type') as user_type,\n",
    "        json_extract_string(userIdentity, '$.userName') as user_name,\n",
    "        COUNT(*) as activity_count,\n",
    "        COUNT(DISTINCT eventName) as unique_actions\n",
    "    FROM cloudtrail \n",
    "    WHERE {date_filter}\n",
    "      AND json_extract_string(userIdentity, '$.type') IS NOT NULL\n",
    "    GROUP BY user_type, user_name\n",
    "    ORDER BY activity_count DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ‘¥ Top Active Users/Roles:\")\n",
    "    users = db.execute_query(users_query)\n",
    "    \n",
    "    if not users.empty:\n",
    "        for _, row in users.iterrows():\n",
    "            user_name = row['user_name'] if row['user_name'] else 'N/A'\n",
    "            print(f\"  {row['user_type']}: {user_name} - {row['activity_count']:,} actions\")\n",
    "    else:\n",
    "        print(\"  No user activity data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ Export disabled. Set EXPORT_RESULTS = True to export analysis results.\n"
     ]
    }
   ],
   "source": [
    "# Optional: Export analysis results\n",
    "EXPORT_RESULTS = False  # Set to True to export\n",
    "\n",
    "if EXPORT_RESULTS and total_events > 0:\n",
    "    export_date = START_DATE.replace('-', '')\n",
    "    export_path = Path(f\"../data/reports/analysis_{export_date}.csv\")\n",
    "    export_path.parent.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Export summary data\n",
    "    summary_query = f\"\"\"\n",
    "    SELECT \n",
    "        eventTime,\n",
    "        eventSource,\n",
    "        eventName,\n",
    "        sourceIPAddress,\n",
    "        json_extract_string(userIdentity, '$.type') as userType\n",
    "    FROM cloudtrail \n",
    "    WHERE {date_filter}\n",
    "    ORDER BY eventTime DESC\n",
    "    LIMIT 1000\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_data = db.execute_query(summary_query)\n",
    "    summary_data.to_csv(export_path, index=False)\n",
    "    print(f\"\\nğŸ’¾ Results exported to: {export_path}\")\n",
    "else:\n",
    "    print(\"\\nğŸ’¾ Export disabled. Set EXPORT_RESULTS = True to export analysis results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Queries - Access Key and Role Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Testing if access key ASIAY5XLNU5IYJANPK4H exists in database (no date filter):\n",
      "[2025-08-08 11:50:39] [INFO] [cloudtrail_analyzer.duckdb_connector] [execute_query] - Query returned 1 rows\n",
      "  âœ… Found 2 events for this access key\n",
      "  ğŸ“… Date range: 2025-07-29 23:58:13 to 2025-07-29 23:58:13\n",
      "  âš ï¸  Note: These events may be outside your configured date range (2025-07-29 to 2025-07-31)\n"
     ]
    }
   ],
   "source": [
    "# Test: Check if access key exists in database without date filter\n",
    "ACCESS_KEY_ID = \"ASIAY5XLNU5IYJANPK4H\"\n",
    "\n",
    "test_query = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_events,\n",
    "    MIN(eventTime) as earliest_event,\n",
    "    MAX(eventTime) as latest_event\n",
    "FROM cloudtrail \n",
    "WHERE json_extract_string(userIdentity, '$.accessKeyId') = '{ACCESS_KEY_ID}'\n",
    "\"\"\"\n",
    "\n",
    "print(f\"ğŸ” Testing if access key {ACCESS_KEY_ID} exists in database (no date filter):\")\n",
    "test_results = db.execute_query(test_query)\n",
    "\n",
    "if test_results.iloc[0]['total_events'] > 0:\n",
    "    print(f\"  âœ… Found {test_results.iloc[0]['total_events']} events for this access key\")\n",
    "    print(f\"  ğŸ“… Date range: {test_results.iloc[0]['earliest_event']} to {test_results.iloc[0]['latest_event']}\")\n",
    "    print(f\"  âš ï¸  Note: These events may be outside your configured date range ({START_DATE}\" + (f\" to {END_DATE}\" if END_DATE else \"\") + \")\")\n",
    "else:\n",
    "    print(f\"  âŒ Access key not found in database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”‘ ACCESS KEY ACTIVITY ANALYSIS\n",
      "==================================================\n",
      "ğŸ” Searching for activity by Access Key: ASIAY5XLNU5IYJANPK4H\n",
      "[2025-08-08 11:50:44] [INFO] [cloudtrail_analyzer.duckdb_connector] [execute_query] - Query returned 2 rows\n",
      "  ğŸ“Š Found 2 events for this access key\n",
      "  ğŸ“… Time range: 2025-07-29 23:58:13 to 2025-07-29 23:58:13\n",
      "  ğŸŒ Unique services: 1\n",
      "  ğŸ¯ Unique actions: 1\n",
      "  ğŸŒ Unique IPs: 1\n",
      "\n",
      "ğŸ† Top Activities:\n",
      "  - DescribeStacks: 2 times\n",
      "\n",
      "ğŸŒ Source IPs:\n",
      "  - ssm-quicksetup.amazonaws.com: 2 events\n"
     ]
    }
   ],
   "source": [
    "if total_events > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ”‘ ACCESS KEY ACTIVITY ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Query for specific Access Key ID activity\n",
    "    ACCESS_KEY_ID = \"ASIAY5XLNU5IYJANPK4H\"  # Change this to your target access key\n",
    "    \n",
    "    access_key_query = f\"\"\"\n",
    "    SELECT \n",
    "        eventTime,\n",
    "        eventName,\n",
    "        eventSource,\n",
    "        sourceIPAddress,\n",
    "        userAgent,\n",
    "        json_extract_string(userIdentity, '$.accessKeyId') as accessKeyId,\n",
    "        json_extract_string(userIdentity, '$.type') as userType,\n",
    "        json_extract_string(userIdentity, '$.userName') as userName,\n",
    "        awsRegion,\n",
    "        requestParameters\n",
    "    FROM cloudtrail \n",
    "    WHERE {date_filter}\n",
    "      AND json_extract_string(userIdentity, '$.accessKeyId') = '{ACCESS_KEY_ID}'\n",
    "    ORDER BY eventTime DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ğŸ” Searching for activity by Access Key: {ACCESS_KEY_ID}\")\n",
    "    access_key_results = db.execute_query(access_key_query)\n",
    "    \n",
    "    if not access_key_results.empty:\n",
    "        print(f\"  ğŸ“Š Found {len(access_key_results)} events for this access key\")\n",
    "        print(f\"  ğŸ“… Time range: {access_key_results['eventTime'].min()} to {access_key_results['eventTime'].max()}\")\n",
    "        print(f\"  ğŸŒ Unique services: {access_key_results['eventSource'].nunique()}\")\n",
    "        print(f\"  ğŸ¯ Unique actions: {access_key_results['eventName'].nunique()}\")\n",
    "        print(f\"  ğŸŒ Unique IPs: {access_key_results['sourceIPAddress'].nunique()}\")\n",
    "        \n",
    "        print(f\"\\nğŸ† Top Activities:\")\n",
    "        top_activities = access_key_results['eventName'].value_counts().head(10)\n",
    "        for activity, count in top_activities.items():\n",
    "            print(f\"  - {activity}: {count} times\")\n",
    "        \n",
    "        print(f\"\\nğŸŒ Source IPs:\")\n",
    "        unique_ips = access_key_results['sourceIPAddress'].value_counts()\n",
    "        for ip, count in unique_ips.items():\n",
    "            print(f\"  - {ip}: {count} events\")\n",
    "    else:\n",
    "        print(f\"  âŒ No activity found for access key: {ACCESS_KEY_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_events > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ‘¤ ROLE ACTIVITY ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Query for specific Role activity\n",
    "    ROLE_NAME = \"AWSServiceRoleForSupport\"  # Change this to your target role\n",
    "    \n",
    "    role_query = f\"\"\"\n",
    "    SELECT \n",
    "        eventTime,\n",
    "        eventName,\n",
    "        eventSource,\n",
    "        sourceIPAddress,\n",
    "        userAgent,\n",
    "        json_extract_string(userIdentity, '$.type') as userType,\n",
    "        json_extract_string(userIdentity, '$.userName') as userName,\n",
    "        json_extract_string(userIdentity, '$.sessionContext.sessionIssuer.userName') as roleName,\n",
    "        json_extract_string(userIdentity, '$.arn') as userArn,\n",
    "        awsRegion,\n",
    "        requestParameters\n",
    "    FROM cloudtrail \n",
    "    WHERE {date_filter}\n",
    "      AND (json_extract_string(userIdentity, '$.userName') LIKE '%{ROLE_NAME}%'\n",
    "           OR json_extract_string(userIdentity, '$.sessionContext.sessionIssuer.userName') LIKE '%{ROLE_NAME}%'\n",
    "           OR json_extract_string(userIdentity, '$.arn') LIKE '%{ROLE_NAME}%')\n",
    "    ORDER BY eventTime DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ğŸ” Searching for activity by Role: {ROLE_NAME}\")\n",
    "    role_results = db.execute_query(role_query)\n",
    "    \n",
    "    if not role_results.empty:\n",
    "        print(f\"  ğŸ“Š Found {len(role_results)} events for this role\")\n",
    "        print(f\"  ğŸ“… Time range: {role_results['eventTime'].min()} to {role_results['eventTime'].max()}\")\n",
    "        print(f\"  ğŸŒ Unique services: {role_results['eventSource'].nunique()}\")\n",
    "        print(f\"  ğŸ¯ Unique actions: {role_results['eventName'].nunique()}\")\n",
    "        print(f\"  ğŸŒ Unique IPs: {role_results['sourceIPAddress'].nunique()}\")\n",
    "        \n",
    "        print(f\"\\nğŸ† Top Activities:\")\n",
    "        top_activities = role_results['eventName'].value_counts().head(10)\n",
    "        for activity, count in top_activities.items():\n",
    "            print(f\"  - {activity}: {count} times\")\n",
    "        \n",
    "        print(f\"\\nğŸŒ Source IPs:\")\n",
    "        unique_ips = role_results['sourceIPAddress'].value_counts()\n",
    "        for ip, count in unique_ips.items():\n",
    "            print(f\"  - {ip}: {count} events\")\n",
    "        \n",
    "        print(f\"\\nğŸ‘¤ User Types:\")\n",
    "        user_types = role_results['userType'].value_counts()\n",
    "        for user_type, count in user_types.items():\n",
    "            print(f\"  - {user_type}: {count} events\")\n",
    "    else:\n",
    "        print(f\"  âŒ No activity found for role: {ROLE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“‹ ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nğŸ“… Analysis Period: {START_DATE}\" + (f\" to {END_DATE}\" if END_DATE else \"\"))\n",
    "print(f\"ğŸ“Š Events Analyzed: {total_events:,}\" if total_events > 0 else \"ğŸ“Š No events found\")\n",
    "print(f\"ğŸ“‚ Data Source: {data_path}\")\n",
    "print(f\"ğŸ’¾ Database: {DB_PATH}\")\n",
    "\n",
    "if available_dates:\n",
    "    print(f\"âœ… Available Dates: {', '.join(available_dates)}\")\n",
    "if missing_dates:\n",
    "    print(f\"âŒ Missing Dates: {', '.join(missing_dates)}\")\n",
    "\n",
    "print(\"\\nğŸ¯ Key Capabilities Demonstrated:\")\n",
    "print(\"  âœ… Configurable date range analysis\")\n",
    "print(\"  âœ… Phase 1 data validation\")\n",
    "print(\"  âœ… Date-filtered security analysis\")\n",
    "print(\"  âœ… Timeline and user activity analysis\")\n",
    "print(\"  âœ… Flexible query framework\")\n",
    "\n",
    "# Close database connection\n",
    "db.close()\n",
    "print(\"\\nğŸ”Œ Database connection closed.\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Configurable Analysis Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
